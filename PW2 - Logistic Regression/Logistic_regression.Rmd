---
title: "Logistic_regression"
output: html_notebook
---
# Social Networks Ads
### 1. Download the Social_Network_Ads dataset and import it into R
```{r}
df <- read.csv("Social_Network_Ads.csv", header=TRUE, sep=",")
df
```

### 2. Download the Social_Network_Ads dataset and import it into R
#### General analysis
```{r}
summary(df)
```
```{r}
str(df)
```
```{r}
plot(df)
```
#### Quantitative features analysis
```{r}
library(corrplot)
M = cor(df[c("Age","EstimatedSalary", "Purchased")])
corrplot.mixed(M)
```

```{r}
boxplot(df$Age)
```
```{r}
boxplot(df$EstimatedSalary)
```

#### Qualitative features analysis
```{r}
pie(table(df$Gender), main="Pie chart of the gender response")
```

#### Target analysis
```{r}
pie(table(df$Purchased), c("Not Purchased", "Purchased"), main="Pie chart of the target")
```

### 3. Now we are going to split the dataset into training set and test set. Last week we did it manually. From now on we will split it randomly, you can use this code (after undestanding it of course):

```{r}
library(caTools) # install it first in the console
set.seed(123)
# we use the function set.seed() with the same seed number
# to randomly generate the same values, you already know that right? 
#and you know why we want to generate the same values, am I wrong? 
split = sample.split(df$Purchased, SplitRatio = 0.75)
# here we chose the SplitRatio to 75% of the dataset,
# and 25% for the test set.
training_set = subset(df, split == TRUE)
# we use subset to split the dataset
test_set = subset(df, split == FALSE)
```

### 4. Scale the input variables in both training set and test set. Do you know what is scaling? Explain it one sentence.

```{r}
training_set$Age = scale(training_set$Age)
training_set$EstimatedSalary = scale(training_set$EstimatedSalary)

test_set$Age = scale(test_set$Age)
test_set$EstimatedSalary = scale(test_set$EstimatedSalary)
```
Scaling is the process of normalizing data.

### 5. Now fit a simple logistic regression model of Purchased in function of Age
```{r}
model_purchased_age = glm(Purchased ~ Age, data = training_set, family = "binomial")
model_purchased_age
```
### 6. As you saw in the Logistic Regression chapter and in the previous question, we choose argument family to be binomial when we use the function glm. Explain why!
glm is the function for generalized linear model, so we need to predict the type (or family) of glm.  
Here we want to predict a binary response so we use the binomial law (a special case for the bernouilli law).

### 7. Write in a equation the model you obtained in question 5?
There are multiples ways to write the logistic function:
$F(X)=\frac{1}{1+e^{-(\beta 0+\beta 1X)}}$
$F(X)=\frac{e^{\beta 0+\beta 1X}}{1+e^{\beta 0+\beta 1X}}$

### 8. Is the feature Age significant to the model? Justify your answer.
```{r}
summary(model_purchased_age)
```
Let's check the p value:    
p_value for Age (<2e-16) < 0.05 (5%)   
So we can say that the feature Age is significant for our model

### 9. What is the value of AIC of the model?
AIC = 256.11

```{r}
typeof(data.frame(Age = x)$Age)
```


### 10. Plot Purchased in function of Age and add the curve of the obtained logistic regression model.

```{r}
library(ggplot2)
ggplot(model_purchased_age, aes(x=Age, y=Purchased)) +
  geom_point() +
  stat_smooth(method="glm", method.args=list(family="binomial"), se=FALSE)
```
### 11. Now let us take another feature into account in the model. Fit a logistic regression model of purchasing the product in function of the age of a user and its salary.
```{r}
model_purchased_age_salary = glm(Purchased ~ Age + EstimatedSalary, data = training_set, family = "binomial")
model_purchased_age_salary
```

### 12. Are the predictors significant to the new model?
```{r}
summary(model_purchased_age_salary)
```
Let's check the p value:    
- p_value for Age (2.83e-14) < 0.05 (5%)   
- p_value for EstimatedSalary (2.03e-09) < 0.05 (5%)   
So we can say that the features Age and EstimatedSalary is significant for our model   

### 13. Do we obtain a better model by adding the estimated salary?
We can use the AIC criteron to compare model to each others.  
    
AIC with the feature age = 256.11  
AIC with the features age and EstimatedSalary = 205.78  
AIC with the features age and EstimatedSalary < AIC with the feature age  
   
So we obtain a better model by adding the estimated salary   

### 14. Predictions: On the test set, predict the probability of purchasing the product by the users using the obtained model.
```{r}
y_hat_purchased_age_salary = predict(model_purchased_age_salary, newdata = test_set[c("Age","EstimatedSalary")], type="response")
y_hat_purchased_age_salary
```

### 15. Take a look on your predicted values for the variable Purchased. We predicted the probability that the user will purchase the product right? Now in order to compare your results with the real answers, transform the predicted values to 0 or 1 (1 if >0.5).
```{r}
y_hat_purchased_age_salary_bin = ifelse(y_hat_purchased_age_salary>0.5,1,0)
y_hat_purchased_age_salary_bin
```

### 16. Now in order to evaluate the model and its predictions, compute the confusion matrix. What do you obtain ?
```{r}
conf_mat = table(y_hat_purchased_age_salary_bin, test_set$Purchased)
conf_mat
```
We obtain the confusion matrix   
True positive  | False negative    
False negative | False positive    

### 17. Calculate the accuracy, specificity, sensitivity and the precision of the model.
```{r}
all_metrics<-function(conf_mat){
accuracy = (conf_mat[1] +  conf_mat[4])/sum(conf_mat)
sensitivity = conf_mat[1]/(conf_mat[1] +  conf_mat[2])
specificity = conf_mat[4]/(conf_mat[3] +  conf_mat[4])
precision  = conf_mat[1]/(conf_mat[1] +  conf_mat[3])
return(list(accuracy = accuracy, sensitivity = sensitivity,
            specificity = specificity, precision = precision))
}

all_metrics(conf_mat)
```

### 18. Plot the ROC curve and calculate AUC value.
```{r}
library(ROCR)
preds = prediction(y_hat_purchased_age_salary, test_set$Purchased)

# TPR: True Positive Rate => sensitivity
# FPR: False Positivity Rate => 1 - TNR (True Negative Rate) => specificity
perf = performance(preds,"tpr","fpr")
plot(perf,col="green", main="ROC curve")
abline(0,1)
```
```{r}
auc = performance(preds, "auc")
auc = auc@y.values[[1]]
auc
```

### 19. Compare the AUC of the two models you fitted (one with only age and one with age and estimated salary) and plot their ROC curves in the same figure.
```{r}
y_hat_purchased_age = predict(model_purchased_age, newdata = test_set[c("Age","EstimatedSalary")], type="response")
y_hat_purchased_age_bin = ifelse(y_hat_purchased_age>0.5,1,0)
y_hat_purchased_age_bin
```


```{r}
preds_purchased_age = prediction(y_hat_purchased_age, test_set$Purchased)
auc_purchased_age = performance(preds_purchased_age, "auc")
auc_purchased_age = auc_purchased_age@y.values[[1]]
auc_purchased_age

preds_purchased_age_salary = prediction(y_hat_purchased_age_salary, test_set$Purchased)
auc_purchased_age_salary = performance(preds_purchased_age_salary, "auc")
auc_purchased_age_salary = auc_purchased_age_salary@y.values[[1]]
auc_purchased_age_salary

preds_purchased_age = prediction(y_hat_purchased_age, test_set$Purchased)
preds_purchased_age_salary = prediction(y_hat_purchased_age_salary, test_set$Purchased)
```
AUC for model with age: 0.8824   
AUC for model with age and EstimatedSalary: 0.9171


```{r}
perf = performance(preds_purchased_age_salary,"tpr","fpr")
plot(perf,col="blue", main="ROC curves")
perf = performance(preds_purchased_age,"tpr","fpr")
plot(perf,col="red", add=TRUE)
abline(0,1)

legend(1, 95, legend=c("Line 1", "Line 2"),
       col=c("red", "blue"), lty=1:2, cex=0.8)
```


